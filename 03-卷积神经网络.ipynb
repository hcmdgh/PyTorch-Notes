{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. nn.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 卷积层的权值矩阵"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 5, 5])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(123)\n",
    "\n",
    "conv = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5)\n",
    "print(conv.weight.shape)  # [out_ch, in_ch, kernel_size, kernel_size]\n",
    "print(conv.bias.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 输入和输出图像的shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 16, 28, 28])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.randn(1000, 3, 32, 32)  # [b, c, h, w]\n",
    "out = conv(img)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Padding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 16, 32, 32])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定padding参数，将对输入图像的四周用0填充\n",
    "conv = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "img = torch.randn(1000, 3, 32, 32)  # [b, c, h, w]\n",
    "out = conv(img)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 1, 2, 3, 0, 0],\n        [0, 0, 4, 5, 6, 0, 0],\n        [0, 0, 7, 8, 9, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 显式Padding的效果演示\n",
    "img = torch.tensor([[1, 2, 3],\n",
    "                    [4, 5, 6],\n",
    "                    [7, 8, 9],])\n",
    "img = nn.ZeroPad2d(2)(img)\n",
    "img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 下采样：从大到小"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 3, 16, 16])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "img = torch.randn(1000, 3, 32, 32)  # [b, c, h, w]\n",
    "out = pool(img)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 网络层搭建"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 失败的尝试"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    # [b, 3, h, w] -> [b, 16, h, w]\n",
    "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "\n",
    "    # [b, 16, h, w] -> [b, 16, h/2, w/2]\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    # [b, 16, h/2, w/2] -> [b, 8, h/2, w/2]\n",
    "    nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "\n",
    "    # [b, 8, h/2, w/2] -> [b, 8, h/4, w/4]\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    # ===此处缺少了将后三个维度打平的过程===\n",
    "    # [b, 8, h/4, w/4] -> [b, 8 * 8 * 8]\n",
    "\n",
    "    # [b, 8 * 8 * 8] -> [b, 32]\n",
    "    nn.Linear(8 * 8 * 8, 32),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 2),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 自定义Module"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 2])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 注意，这些子Module必须是顶级属性，才会被加入到\n",
    "        # 主Module的参数列表中。如果将子Module包裹在list\n",
    "        # 或dict中，它们并不会被加入到主Module的参数列表，\n",
    "        # 因此参数得不到更新。如果确实需要使用list或dict，\n",
    "        # 可以使用nn.ModuleList或nn.ModuleDict。\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "\n",
    "        # [b, 8, h/4, w/4] -> [b, -1]\n",
    "        out = out.view(out.shape[0], -1)\n",
    "\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "img = torch.randn(1000, 3, 32, 32)  # [b, c, h, w]\n",
    "model = MyNet()\n",
    "out = model(img)\n",
    "out.shape  # [b, 2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18090\n",
      "18090\n"
     ]
    }
   ],
   "source": [
    "# 参数量统计\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 Functional API\n",
    "\n",
    "除了nn.Tanh()这样的网络层类，PyTorch还提供了相应的函数，\n",
    "这些函数没有中间状态，即它的输出完全依赖于输入。\n",
    "\n",
    "因此可以将上述自定义Module改写为："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 2])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MyNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "img = torch.randn(1000, 3, 32, 32)  # [b, c, h, w]\n",
    "model = MyNet2()\n",
    "out = model(img)\n",
    "out.shape  # [b, 2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18090\n",
      "18090\n"
     ]
    }
   ],
   "source": [
    "# 参数量统计\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 训练主函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(input=outputs, target=labels)\n",
    "\n",
    "            # 用梯度信息更新模型参数\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 以下两种写法完全相同\n",
    "            # total_loss += float(loss)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"epoch: {epoch} training loss: {total_loss / len(train_loader)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 数据集的加载（同02）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "DATA_PATH = \"./data/datasets\"\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    DATA_PATH,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4915, 0.4823, 0.4468],\n",
    "                             [0.2470, 0.2435, 0.2616],),\n",
    "    ]),\n",
    ")\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    DATA_PATH,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4915, 0.4823, 0.4468],\n",
    "                             [0.2470, 0.2435, 0.2616],),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "label_map = {0: 0, 2: 1}  # 原始数据集中 0: airplane 2:bird\n",
    "cifar2_train = [(img, label_map[label]) for img, label in cifar10_train if label in (0, 2)]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in (0, 2)]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3 训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss: 0.5722224509260457\n",
      "epoch: 1 training loss: 0.48653622778357974\n",
      "epoch: 2 training loss: 0.459078013327471\n",
      "epoch: 3 training loss: 0.43603592256831514\n",
      "epoch: 4 training loss: 0.40733177210115323\n",
      "epoch: 5 training loss: 0.38148498990733154\n",
      "epoch: 6 training loss: 0.36367156275898027\n",
      "epoch: 7 training loss: 0.3476295379126907\n",
      "epoch: 8 training loss: 0.33781792821398204\n",
      "epoch: 9 training loss: 0.33118677186738155\n"
     ]
    }
   ],
   "source": [
    "model = MyNet2()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs=10,\n",
    "              optimizer=optimizer,\n",
    "              model=model,\n",
    "              loss_fn=loss_fn,\n",
    "              train_loader=train_loader,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. 测试"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.8565\n",
      "Accuracy val: 0.8515\n"
     ]
    }
   ],
   "source": [
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        correct = total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((pred == labels).sum())\n",
    "\n",
    "        print(f\"Accuracy {name}: {correct / total}\")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. 保存和加载模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.1 保存模型到文件"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./data/conv.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6.2 从文件载入模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 需要保证模型的结构不变\n",
    "# 文件中仅仅保存了模型的参数值\n",
    "loaded_model = MyNet2()\n",
    "loaded_model.load_state_dict(torch.load(\"././data/conv.pt\"))\n",
    "# 注：load_state_dict()方法接收map_location=device参数，可以指定参数被载入的设备"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. 使用GPU训练\n",
    "\n",
    "Module和Tensor都可以调用to()方法将其转移到GPU上，\n",
    "但是Module.to()是原地的，Tensor.to()返回新的对象，\n",
    "因此创建Optimizer需要在所有参数移到GPU以后进行。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取可用设备\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 training loss: 0.6250360036731526\n",
      "epoch: 1 training loss: 0.5023902062397854\n",
      "epoch: 2 training loss: 0.4668117000418863\n",
      "epoch: 3 training loss: 0.4298659238466032\n",
      "epoch: 4 training loss: 0.39260457864232884\n",
      "epoch: 5 training loss: 0.36830267585386894\n",
      "epoch: 6 training loss: 0.3514456562935167\n",
      "epoch: 7 training loss: 0.3410620111378895\n",
      "epoch: 8 training loss: 0.33337449135294384\n",
      "epoch: 9 training loss: 0.32586679868637375\n"
     ]
    }
   ],
   "source": [
    "# 以下训练过程与之前相比只做了微小的改动\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(input=outputs, target=labels)\n",
    "\n",
    "            # 用梯度信息更新模型参数\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"epoch: {epoch} training loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "model = MyNet2().to(device=device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs=10,\n",
    "              optimizer=optimizer,\n",
    "              model=model,\n",
    "              loss_fn=loss_fn,\n",
    "              train_loader=train_loader,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-418948df",
   "language": "python",
   "display_name": "PyCharm (ACM-Py)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}