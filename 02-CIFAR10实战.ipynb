{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 载入CIFAR10数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/datasets\"\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    DATA_PATH,\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4915, 0.4823, 0.4468],\n",
    "                             [0.2470, 0.2435, 0.2616],),\n",
    "    ]),\n",
    ")\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    DATA_PATH,\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.4915, 0.4823, 0.4468],\n",
    "                             [0.2470, 0.2435, 0.2616],),\n",
    "    ]),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 2000)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 本例只需要区分airplane和bird\n",
    "# 因此从整个数据集中抽取airplane和bird\n",
    "label_map = {0: 0, 2: 1}  # 原始数据集中 0: airplane 2:bird\n",
    "cifar2_train = [(img, label_map[label]) for img, label in cifar10_train if label in (0, 2)]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in (0, 2)]\n",
    "len(cifar2_train), len(cifar2_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "# 使用DataLoader的两个好处：\n",
    "# 1. 可以指定batch_size\n",
    "# 2. 可以在每个epoch开始前shuffle整个数据集\n",
    "BATCH_SIZE = 64\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Softmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.0321, 0.0871, 0.2369, 0.6439])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Softmax：将一个向量转换使其符合概率分布\n",
    "t1 = torch.tensor([1., 2., 3., 4.])\n",
    "softmax = torch.nn.Softmax(dim=-1)  # 指定Softmax操作的维度\n",
    "softmax(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n        [0.0321, 0.0871, 0.2369, 0.6439]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([[1., 2., 3., 4.],\n",
    "                   [1., 2., 3., 4.]])\n",
    "softmax(t2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-3.4402, -2.4402, -1.4402, -0.4402])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogSoftmax：对Softmax的结果取对数\n",
    "# 解决了当概率趋于0时求log易出错的问题\n",
    "t1 = torch.tensor([1., 2., 3., 4.])\n",
    "torch.nn.LogSoftmax(dim=-1)(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-3.4402, -2.4402, -1.4402, -0.4402])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(softmax(t1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. NLL(negative log likelihood)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.5742,  0.3406,  0.1690,  0.0942],\n        [-0.5183,  0.0804,  0.0863,  0.6098],\n        [ 0.7201,  0.3580,  0.0738, -1.2240]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 假设神经网络输出的shape为(3, 4)，3是图片数量，4是分类个数\n",
    "out = torch.randn(3, 4)\n",
    "out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-2.0216, -1.1068, -1.2784, -1.3531],\n        [-2.0464, -1.4477, -1.4418, -0.9183],\n        [-0.8600, -1.2222, -1.5064, -2.8042]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = torch.nn.LogSoftmax(dim=-1)(out)\n",
    "tmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.4821)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLL = - sum(log(对应类别的prob))\n",
    "loss = torch.nn.NLLLoss()\n",
    "target = torch.tensor([0, 3, 2])  # 3张图片对应的类别\n",
    "loss(input=tmp, target=target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.4821)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(tmp[0][0] + tmp[1][3] + tmp[2][2]) / 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Cross Entropy Loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.4821)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.CrossEntropyLoss即为nn.LogSoftmax和nn.NLLLoss的整合\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "loss(input=out, target=target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. 创建网络层"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(32 * 32 * 3, 1024),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(1024, 512),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(256, 128),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(128, 64),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(64, 2),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. 训练"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 0.6405237317085266\n",
      "epoch: 1 loss: 0.6103984713554382\n",
      "epoch: 2 loss: 0.5862966775894165\n",
      "epoch: 3 loss: 0.5428605079650879\n",
      "epoch: 4 loss: 0.6126407384872437\n",
      "epoch: 5 loss: 0.6868407130241394\n",
      "epoch: 6 loss: 0.43032869696617126\n",
      "epoch: 7 loss: 0.4288029372692108\n",
      "epoch: 8 loss: 0.5740498900413513\n",
      "epoch: 9 loss: 0.6416813135147095\n",
      "epoch: 10 loss: 0.6376734972000122\n",
      "epoch: 11 loss: 0.5493194460868835\n",
      "epoch: 12 loss: 0.5485740900039673\n",
      "epoch: 13 loss: 0.46325165033340454\n",
      "epoch: 14 loss: 0.3338705599308014\n",
      "epoch: 15 loss: 0.4930219054222107\n",
      "epoch: 16 loss: 0.4548221826553345\n",
      "epoch: 17 loss: 0.43117886781692505\n",
      "epoch: 18 loss: 0.4639514684677124\n",
      "epoch: 19 loss: 0.5549517869949341\n",
      "epoch: 20 loss: 0.5419827103614807\n",
      "epoch: 21 loss: 0.26175540685653687\n",
      "epoch: 22 loss: 0.5439325571060181\n",
      "epoch: 23 loss: 0.553778886795044\n",
      "epoch: 24 loss: 0.6260469555854797\n",
      "epoch: 25 loss: 0.5388987064361572\n",
      "epoch: 26 loss: 0.2847745418548584\n",
      "epoch: 27 loss: 0.4176800847053528\n",
      "epoch: 28 loss: 0.6171953678131104\n",
      "epoch: 29 loss: 0.3992089629173279\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        # img: [b, 3, 32, 32] -> [b, -1]\n",
    "        # out: [b, 2]\n",
    "        batch_size = imgs.shape[0]\n",
    "        out = model(imgs.reshape(batch_size, -1))\n",
    "        loss = loss_fn(input=out, target=labels)\n",
    "\n",
    "        # 清零梯度信息\n",
    "        optimizer.zero_grad()\n",
    "        # 计算loss的梯度\n",
    "        loss.backward()\n",
    "        # 用梯度更新模型参数\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"epoch: {epoch} loss: {float(loss)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. 测试"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "correct = total = 0\n",
    "\n",
    "# 在inference过程，需要禁止梯度计算\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.reshape(batch_size, -1))\n",
    "        _, pred = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((pred == labels).sum())\n",
    "\n",
    "    print(f\"Accuracy: {correct / total}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-418948df",
   "language": "python",
   "display_name": "PyCharm (ACM-Py)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}